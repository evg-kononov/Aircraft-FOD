{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\tf-torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchinfo\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [],
   "source": [
    "import torchmetrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "outputs": [],
   "source": [
    "task = \"multiclass\"\n",
    "top_k = 1\n",
    "accuracy = torchmetrics.classification.Accuracy(task=task, threshold=0.5, num_classes=10, top_k=top_k).to(\"cuda\")\n",
    "precision = torchmetrics.Precision(task=task, threshold=0.5, num_classes=10, top_k=top_k).to(\"cuda\")\n",
    "recall = torchmetrics.Recall(task=task, threshold=0.5, num_classes=10, top_k=top_k).to(\"cuda\")\n",
    "f1 = torchmetrics.F1Score(task=task, threshold=0.5, num_classes=10, top_k=top_k).to(\"cuda\")\n",
    "stat = torchmetrics.StatScores(task=task, threshold=0.5, num_classes=10, top_k=top_k).to(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  9, 81,  9, 10], device='cuda:0')\n",
      "tensor(0.1000, device='cuda:0')\n",
      "tensor(0.1000, device='cuda:0')\n",
      "tensor(0.1000, device='cuda:0')\n",
      "tensor(0.1000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "preds = torch.tensor([[-0.0129, -0.3175, -0.0683,  0.2080,  0.1129,  0.0553,  0.0140,  0.0251,\n",
    "         -0.1527,  0.0622],\n",
    "        [ 0.1304,  0.1785,  0.0883,  0.5066, -0.1161, -0.1496, -0.2035,  0.0709,\n",
    "          0.2420,  0.3981],\n",
    "        [-0.0213, -0.0850, -0.1686,  0.1521,  0.2414, -0.0275,  0.0066,  0.1848,\n",
    "         -0.1766,  0.0321],\n",
    "        [ 0.3734,  0.3885, -0.2002, -0.3148, -0.2604,  0.3571, -0.7075, -0.2140,\n",
    "          0.2051,  0.7275],\n",
    "        [-0.1535, -0.1203, -0.0069,  0.2753,  0.3317, -0.3602, -0.1358,  0.1422,\n",
    "         -0.0302,  0.3005],\n",
    "        [ 0.2874,  0.1921,  0.2205,  0.3036, -0.1055, -0.1325,  0.0322,  0.4317,\n",
    "          0.1032, -0.0067],\n",
    "        [ 0.0414, -0.1034, -0.1293,  0.0489,  0.3273,  0.1023, -0.1438,  0.1175,\n",
    "         -0.0843,  0.1121],\n",
    "        [-0.1684, -0.0975, -0.1321,  0.1957,  0.1615,  0.1282, -0.2379,  0.0721,\n",
    "         -0.1267,  0.1032],\n",
    "        [ 0.0425, -0.1601, -0.0020,  0.1313,  0.1604,  0.1026,  0.0792,  0.1182,\n",
    "         -0.0664,  0.0552],\n",
    "        [-0.0258, -0.2268, -0.0416,  0.0605,  0.1985,  0.0211, -0.2180,  0.1641,\n",
    "         -0.0347, -0.0319]]).to(\"cuda\")\n",
    "target = torch.tensor([3, 7, 0, 1, 3, 8, 9, 8, 3, 6]).to(\"cuda\")\n",
    "print(stat(preds, target))\n",
    "print(accuracy(preds, target))\n",
    "print(precision(preds, target))\n",
    "print(recall(preds, target))\n",
    "print(f1(preds, target))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4, 46, 44,  6, 10], device='cuda:0')\n",
      "tensor(0.4000, device='cuda:0')\n",
      "tensor(0.0800, device='cuda:0')\n",
      "tensor(0.4000, device='cuda:0')\n",
      "tensor(0.1333, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(stat.compute())\n",
    "print(accuracy.compute())\n",
    "print(precision.compute())\n",
    "print(recall.compute())\n",
    "print(f1.compute())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [
    "root_path = f\"C:/Users/conon/Documents/Datasets/cifar10/\"\n",
    "train_path = os.path.join(root_path, \"train\")\n",
    "val_path = os.path.join(root_path, \"test\")\n",
    "\n",
    "train_labels_path = os.path.join(root_path, \"train_labels.csv\")\n",
    "val_labels_path = os.path.join(root_path, \"test_labels.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train = datasets.CIFAR10(root=root_path, train=True, download=True)\n",
    "val = datasets.CIFAR10(root=root_path, train=False, download=True)\n",
    "\n",
    "for i, img in enumerate(train.data):\n",
    "     np.save(os.path.join(root_path + \"train\", str(i)), img)\n",
    "pd.DataFrame({\"label\": train.targets}).to_csv(train_labels_path, index=True)\n",
    "for i, img in enumerate(val.data):\n",
    "     np.save(os.path.join(root_path + \"test\", str(i)), img)\n",
    "pd.DataFrame({\"label\": val.targets}).to_csv(val_labels_path, index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "data": {
      "text/plain": "['vgg11.tv_in1k',\n 'vgg11_bn.tv_in1k',\n 'vgg13.tv_in1k',\n 'vgg13_bn.tv_in1k',\n 'vgg16.tv_in1k',\n 'vgg16_bn.tv_in1k',\n 'vgg19.tv_in1k',\n 'vgg19_bn.tv_in1k']"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(\"vgg*\", pretrained=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 531M/531M [00:50<00:00, 10.6MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model(\"vgg11\", pretrained=True, num_classes=10, in_chans=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nVGG                                      [1, 10]                   --\n├─Sequential: 1-1                        [1, 512, 1, 1]            --\n│    └─Conv2d: 2-1                       [1, 64, 32, 32]           1,792\n│    └─ReLU: 2-2                         [1, 64, 32, 32]           --\n│    └─MaxPool2d: 2-3                    [1, 64, 16, 16]           --\n│    └─Conv2d: 2-4                       [1, 128, 16, 16]          73,856\n│    └─ReLU: 2-5                         [1, 128, 16, 16]          --\n│    └─MaxPool2d: 2-6                    [1, 128, 8, 8]            --\n│    └─Conv2d: 2-7                       [1, 256, 8, 8]            295,168\n│    └─ReLU: 2-8                         [1, 256, 8, 8]            --\n│    └─Conv2d: 2-9                       [1, 256, 8, 8]            590,080\n│    └─ReLU: 2-10                        [1, 256, 8, 8]            --\n│    └─MaxPool2d: 2-11                   [1, 256, 4, 4]            --\n│    └─Conv2d: 2-12                      [1, 512, 4, 4]            1,180,160\n│    └─ReLU: 2-13                        [1, 512, 4, 4]            --\n│    └─Conv2d: 2-14                      [1, 512, 4, 4]            2,359,808\n│    └─ReLU: 2-15                        [1, 512, 4, 4]            --\n│    └─MaxPool2d: 2-16                   [1, 512, 2, 2]            --\n│    └─Conv2d: 2-17                      [1, 512, 2, 2]            2,359,808\n│    └─ReLU: 2-18                        [1, 512, 2, 2]            --\n│    └─Conv2d: 2-19                      [1, 512, 2, 2]            2,359,808\n│    └─ReLU: 2-20                        [1, 512, 2, 2]            --\n│    └─MaxPool2d: 2-21                   [1, 512, 1, 1]            --\n├─ConvMlp: 1-2                           [1, 4096, 1, 1]           --\n│    └─Conv2d: 2-22                      [1, 4096, 1, 1]           102,764,544\n│    └─ReLU: 2-23                        [1, 4096, 1, 1]           --\n│    └─Dropout: 2-24                     [1, 4096, 1, 1]           --\n│    └─Conv2d: 2-25                      [1, 4096, 1, 1]           16,781,312\n│    └─ReLU: 2-26                        [1, 4096, 1, 1]           --\n├─ClassifierHead: 1-3                    [1, 10]                   --\n│    └─SelectAdaptivePool2d: 2-27        [1, 4096]                 --\n│    │    └─AdaptiveAvgPool2d: 3-1       [1, 4096, 1, 1]           --\n│    │    └─Flatten: 3-2                 [1, 4096]                 --\n│    └─Dropout: 2-28                     [1, 4096]                 --\n│    └─Linear: 2-29                      [1, 10]                   40,970\n│    └─Identity: 2-30                    [1, 10]                   --\n==========================================================================================\nTotal params: 128,807,306\nTrainable params: 128,807,306\nNon-trainable params: 0\nTotal mult-adds (M): 272.50\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 1.28\nParams size (MB): 515.23\nEstimated Total Size (MB): 516.52\n=========================================================================================="
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model, input_size=[1, 3, 32, 32], depth=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "param_name = [name for name,_ in model.named_parameters()] # All parameters name\n",
    "layer_name = [name for name,_ in model.named_modules()] # All layers name"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "data": {
      "text/plain": "['conv_stem.weight',\n 'bn1.weight',\n 'bn1.bias',\n 'blocks.0.0.conv_dw.weight',\n 'blocks.0.0.bn1.weight',\n 'blocks.0.0.bn1.bias',\n 'blocks.0.0.se.conv_reduce.weight',\n 'blocks.0.0.se.conv_reduce.bias',\n 'blocks.0.0.se.conv_expand.weight',\n 'blocks.0.0.se.conv_expand.bias',\n 'blocks.0.0.conv_pw.weight',\n 'blocks.0.0.bn2.weight',\n 'blocks.0.0.bn2.bias',\n 'blocks.0.1.conv_dw.weight',\n 'blocks.0.1.bn1.weight',\n 'blocks.0.1.bn1.bias',\n 'blocks.0.1.se.conv_reduce.weight',\n 'blocks.0.1.se.conv_reduce.bias',\n 'blocks.0.1.se.conv_expand.weight',\n 'blocks.0.1.se.conv_expand.bias',\n 'blocks.0.1.conv_pw.weight',\n 'blocks.0.1.bn2.weight',\n 'blocks.0.1.bn2.bias',\n 'blocks.1.0.conv_pw.weight',\n 'blocks.1.0.bn1.weight',\n 'blocks.1.0.bn1.bias',\n 'blocks.1.0.conv_dw.weight',\n 'blocks.1.0.bn2.weight',\n 'blocks.1.0.bn2.bias',\n 'blocks.1.0.se.conv_reduce.weight',\n 'blocks.1.0.se.conv_reduce.bias',\n 'blocks.1.0.se.conv_expand.weight',\n 'blocks.1.0.se.conv_expand.bias',\n 'blocks.1.0.conv_pwl.weight',\n 'blocks.1.0.bn3.weight',\n 'blocks.1.0.bn3.bias',\n 'blocks.1.1.conv_pw.weight',\n 'blocks.1.1.bn1.weight',\n 'blocks.1.1.bn1.bias',\n 'blocks.1.1.conv_dw.weight',\n 'blocks.1.1.bn2.weight',\n 'blocks.1.1.bn2.bias',\n 'blocks.1.1.se.conv_reduce.weight',\n 'blocks.1.1.se.conv_reduce.bias',\n 'blocks.1.1.se.conv_expand.weight',\n 'blocks.1.1.se.conv_expand.bias',\n 'blocks.1.1.conv_pwl.weight',\n 'blocks.1.1.bn3.weight',\n 'blocks.1.1.bn3.bias',\n 'blocks.1.2.conv_pw.weight',\n 'blocks.1.2.bn1.weight',\n 'blocks.1.2.bn1.bias',\n 'blocks.1.2.conv_dw.weight',\n 'blocks.1.2.bn2.weight',\n 'blocks.1.2.bn2.bias',\n 'blocks.1.2.se.conv_reduce.weight',\n 'blocks.1.2.se.conv_reduce.bias',\n 'blocks.1.2.se.conv_expand.weight',\n 'blocks.1.2.se.conv_expand.bias',\n 'blocks.1.2.conv_pwl.weight',\n 'blocks.1.2.bn3.weight',\n 'blocks.1.2.bn3.bias',\n 'blocks.2.0.conv_pw.weight',\n 'blocks.2.0.bn1.weight',\n 'blocks.2.0.bn1.bias',\n 'blocks.2.0.conv_dw.weight',\n 'blocks.2.0.bn2.weight',\n 'blocks.2.0.bn2.bias',\n 'blocks.2.0.se.conv_reduce.weight',\n 'blocks.2.0.se.conv_reduce.bias',\n 'blocks.2.0.se.conv_expand.weight',\n 'blocks.2.0.se.conv_expand.bias',\n 'blocks.2.0.conv_pwl.weight',\n 'blocks.2.0.bn3.weight',\n 'blocks.2.0.bn3.bias',\n 'blocks.2.1.conv_pw.weight',\n 'blocks.2.1.bn1.weight',\n 'blocks.2.1.bn1.bias',\n 'blocks.2.1.conv_dw.weight',\n 'blocks.2.1.bn2.weight',\n 'blocks.2.1.bn2.bias',\n 'blocks.2.1.se.conv_reduce.weight',\n 'blocks.2.1.se.conv_reduce.bias',\n 'blocks.2.1.se.conv_expand.weight',\n 'blocks.2.1.se.conv_expand.bias',\n 'blocks.2.1.conv_pwl.weight',\n 'blocks.2.1.bn3.weight',\n 'blocks.2.1.bn3.bias',\n 'blocks.2.2.conv_pw.weight',\n 'blocks.2.2.bn1.weight',\n 'blocks.2.2.bn1.bias',\n 'blocks.2.2.conv_dw.weight',\n 'blocks.2.2.bn2.weight',\n 'blocks.2.2.bn2.bias',\n 'blocks.2.2.se.conv_reduce.weight',\n 'blocks.2.2.se.conv_reduce.bias',\n 'blocks.2.2.se.conv_expand.weight',\n 'blocks.2.2.se.conv_expand.bias',\n 'blocks.2.2.conv_pwl.weight',\n 'blocks.2.2.bn3.weight',\n 'blocks.2.2.bn3.bias',\n 'blocks.3.0.conv_pw.weight',\n 'blocks.3.0.bn1.weight',\n 'blocks.3.0.bn1.bias',\n 'blocks.3.0.conv_dw.weight',\n 'blocks.3.0.bn2.weight',\n 'blocks.3.0.bn2.bias',\n 'blocks.3.0.se.conv_reduce.weight',\n 'blocks.3.0.se.conv_reduce.bias',\n 'blocks.3.0.se.conv_expand.weight',\n 'blocks.3.0.se.conv_expand.bias',\n 'blocks.3.0.conv_pwl.weight',\n 'blocks.3.0.bn3.weight',\n 'blocks.3.0.bn3.bias',\n 'blocks.3.1.conv_pw.weight',\n 'blocks.3.1.bn1.weight',\n 'blocks.3.1.bn1.bias',\n 'blocks.3.1.conv_dw.weight',\n 'blocks.3.1.bn2.weight',\n 'blocks.3.1.bn2.bias',\n 'blocks.3.1.se.conv_reduce.weight',\n 'blocks.3.1.se.conv_reduce.bias',\n 'blocks.3.1.se.conv_expand.weight',\n 'blocks.3.1.se.conv_expand.bias',\n 'blocks.3.1.conv_pwl.weight',\n 'blocks.3.1.bn3.weight',\n 'blocks.3.1.bn3.bias',\n 'blocks.3.2.conv_pw.weight',\n 'blocks.3.2.bn1.weight',\n 'blocks.3.2.bn1.bias',\n 'blocks.3.2.conv_dw.weight',\n 'blocks.3.2.bn2.weight',\n 'blocks.3.2.bn2.bias',\n 'blocks.3.2.se.conv_reduce.weight',\n 'blocks.3.2.se.conv_reduce.bias',\n 'blocks.3.2.se.conv_expand.weight',\n 'blocks.3.2.se.conv_expand.bias',\n 'blocks.3.2.conv_pwl.weight',\n 'blocks.3.2.bn3.weight',\n 'blocks.3.2.bn3.bias',\n 'blocks.3.3.conv_pw.weight',\n 'blocks.3.3.bn1.weight',\n 'blocks.3.3.bn1.bias',\n 'blocks.3.3.conv_dw.weight',\n 'blocks.3.3.bn2.weight',\n 'blocks.3.3.bn2.bias',\n 'blocks.3.3.se.conv_reduce.weight',\n 'blocks.3.3.se.conv_reduce.bias',\n 'blocks.3.3.se.conv_expand.weight',\n 'blocks.3.3.se.conv_expand.bias',\n 'blocks.3.3.conv_pwl.weight',\n 'blocks.3.3.bn3.weight',\n 'blocks.3.3.bn3.bias',\n 'blocks.3.4.conv_pw.weight',\n 'blocks.3.4.bn1.weight',\n 'blocks.3.4.bn1.bias',\n 'blocks.3.4.conv_dw.weight',\n 'blocks.3.4.bn2.weight',\n 'blocks.3.4.bn2.bias',\n 'blocks.3.4.se.conv_reduce.weight',\n 'blocks.3.4.se.conv_reduce.bias',\n 'blocks.3.4.se.conv_expand.weight',\n 'blocks.3.4.se.conv_expand.bias',\n 'blocks.3.4.conv_pwl.weight',\n 'blocks.3.4.bn3.weight',\n 'blocks.3.4.bn3.bias',\n 'blocks.4.0.conv_pw.weight',\n 'blocks.4.0.bn1.weight',\n 'blocks.4.0.bn1.bias',\n 'blocks.4.0.conv_dw.weight',\n 'blocks.4.0.bn2.weight',\n 'blocks.4.0.bn2.bias',\n 'blocks.4.0.se.conv_reduce.weight',\n 'blocks.4.0.se.conv_reduce.bias',\n 'blocks.4.0.se.conv_expand.weight',\n 'blocks.4.0.se.conv_expand.bias',\n 'blocks.4.0.conv_pwl.weight',\n 'blocks.4.0.bn3.weight',\n 'blocks.4.0.bn3.bias',\n 'blocks.4.1.conv_pw.weight',\n 'blocks.4.1.bn1.weight',\n 'blocks.4.1.bn1.bias',\n 'blocks.4.1.conv_dw.weight',\n 'blocks.4.1.bn2.weight',\n 'blocks.4.1.bn2.bias',\n 'blocks.4.1.se.conv_reduce.weight',\n 'blocks.4.1.se.conv_reduce.bias',\n 'blocks.4.1.se.conv_expand.weight',\n 'blocks.4.1.se.conv_expand.bias',\n 'blocks.4.1.conv_pwl.weight',\n 'blocks.4.1.bn3.weight',\n 'blocks.4.1.bn3.bias',\n 'blocks.4.2.conv_pw.weight',\n 'blocks.4.2.bn1.weight',\n 'blocks.4.2.bn1.bias',\n 'blocks.4.2.conv_dw.weight',\n 'blocks.4.2.bn2.weight',\n 'blocks.4.2.bn2.bias',\n 'blocks.4.2.se.conv_reduce.weight',\n 'blocks.4.2.se.conv_reduce.bias',\n 'blocks.4.2.se.conv_expand.weight',\n 'blocks.4.2.se.conv_expand.bias',\n 'blocks.4.2.conv_pwl.weight',\n 'blocks.4.2.bn3.weight',\n 'blocks.4.2.bn3.bias',\n 'blocks.4.3.conv_pw.weight',\n 'blocks.4.3.bn1.weight',\n 'blocks.4.3.bn1.bias',\n 'blocks.4.3.conv_dw.weight',\n 'blocks.4.3.bn2.weight',\n 'blocks.4.3.bn2.bias',\n 'blocks.4.3.se.conv_reduce.weight',\n 'blocks.4.3.se.conv_reduce.bias',\n 'blocks.4.3.se.conv_expand.weight',\n 'blocks.4.3.se.conv_expand.bias',\n 'blocks.4.3.conv_pwl.weight',\n 'blocks.4.3.bn3.weight',\n 'blocks.4.3.bn3.bias',\n 'blocks.4.4.conv_pw.weight',\n 'blocks.4.4.bn1.weight',\n 'blocks.4.4.bn1.bias',\n 'blocks.4.4.conv_dw.weight',\n 'blocks.4.4.bn2.weight',\n 'blocks.4.4.bn2.bias',\n 'blocks.4.4.se.conv_reduce.weight',\n 'blocks.4.4.se.conv_reduce.bias',\n 'blocks.4.4.se.conv_expand.weight',\n 'blocks.4.4.se.conv_expand.bias',\n 'blocks.4.4.conv_pwl.weight',\n 'blocks.4.4.bn3.weight',\n 'blocks.4.4.bn3.bias',\n 'blocks.5.0.conv_pw.weight',\n 'blocks.5.0.bn1.weight',\n 'blocks.5.0.bn1.bias',\n 'blocks.5.0.conv_dw.weight',\n 'blocks.5.0.bn2.weight',\n 'blocks.5.0.bn2.bias',\n 'blocks.5.0.se.conv_reduce.weight',\n 'blocks.5.0.se.conv_reduce.bias',\n 'blocks.5.0.se.conv_expand.weight',\n 'blocks.5.0.se.conv_expand.bias',\n 'blocks.5.0.conv_pwl.weight',\n 'blocks.5.0.bn3.weight',\n 'blocks.5.0.bn3.bias',\n 'blocks.5.1.conv_pw.weight',\n 'blocks.5.1.bn1.weight',\n 'blocks.5.1.bn1.bias',\n 'blocks.5.1.conv_dw.weight',\n 'blocks.5.1.bn2.weight',\n 'blocks.5.1.bn2.bias',\n 'blocks.5.1.se.conv_reduce.weight',\n 'blocks.5.1.se.conv_reduce.bias',\n 'blocks.5.1.se.conv_expand.weight',\n 'blocks.5.1.se.conv_expand.bias',\n 'blocks.5.1.conv_pwl.weight',\n 'blocks.5.1.bn3.weight',\n 'blocks.5.1.bn3.bias',\n 'blocks.5.2.conv_pw.weight',\n 'blocks.5.2.bn1.weight',\n 'blocks.5.2.bn1.bias',\n 'blocks.5.2.conv_dw.weight',\n 'blocks.5.2.bn2.weight',\n 'blocks.5.2.bn2.bias',\n 'blocks.5.2.se.conv_reduce.weight',\n 'blocks.5.2.se.conv_reduce.bias',\n 'blocks.5.2.se.conv_expand.weight',\n 'blocks.5.2.se.conv_expand.bias',\n 'blocks.5.2.conv_pwl.weight',\n 'blocks.5.2.bn3.weight',\n 'blocks.5.2.bn3.bias',\n 'blocks.5.3.conv_pw.weight',\n 'blocks.5.3.bn1.weight',\n 'blocks.5.3.bn1.bias',\n 'blocks.5.3.conv_dw.weight',\n 'blocks.5.3.bn2.weight',\n 'blocks.5.3.bn2.bias',\n 'blocks.5.3.se.conv_reduce.weight',\n 'blocks.5.3.se.conv_reduce.bias',\n 'blocks.5.3.se.conv_expand.weight',\n 'blocks.5.3.se.conv_expand.bias',\n 'blocks.5.3.conv_pwl.weight',\n 'blocks.5.3.bn3.weight',\n 'blocks.5.3.bn3.bias',\n 'blocks.5.4.conv_pw.weight',\n 'blocks.5.4.bn1.weight',\n 'blocks.5.4.bn1.bias',\n 'blocks.5.4.conv_dw.weight',\n 'blocks.5.4.bn2.weight',\n 'blocks.5.4.bn2.bias',\n 'blocks.5.4.se.conv_reduce.weight',\n 'blocks.5.4.se.conv_reduce.bias',\n 'blocks.5.4.se.conv_expand.weight',\n 'blocks.5.4.se.conv_expand.bias',\n 'blocks.5.4.conv_pwl.weight',\n 'blocks.5.4.bn3.weight',\n 'blocks.5.4.bn3.bias',\n 'blocks.5.5.conv_pw.weight',\n 'blocks.5.5.bn1.weight',\n 'blocks.5.5.bn1.bias',\n 'blocks.5.5.conv_dw.weight',\n 'blocks.5.5.bn2.weight',\n 'blocks.5.5.bn2.bias',\n 'blocks.5.5.se.conv_reduce.weight',\n 'blocks.5.5.se.conv_reduce.bias',\n 'blocks.5.5.se.conv_expand.weight',\n 'blocks.5.5.se.conv_expand.bias',\n 'blocks.5.5.conv_pwl.weight',\n 'blocks.5.5.bn3.weight',\n 'blocks.5.5.bn3.bias',\n 'blocks.6.0.conv_pw.weight',\n 'blocks.6.0.bn1.weight',\n 'blocks.6.0.bn1.bias',\n 'blocks.6.0.conv_dw.weight',\n 'blocks.6.0.bn2.weight',\n 'blocks.6.0.bn2.bias',\n 'blocks.6.0.se.conv_reduce.weight',\n 'blocks.6.0.se.conv_reduce.bias',\n 'blocks.6.0.se.conv_expand.weight',\n 'blocks.6.0.se.conv_expand.bias',\n 'blocks.6.0.conv_pwl.weight',\n 'blocks.6.0.bn3.weight',\n 'blocks.6.0.bn3.bias',\n 'blocks.6.1.conv_pw.weight',\n 'blocks.6.1.bn1.weight',\n 'blocks.6.1.bn1.bias',\n 'blocks.6.1.conv_dw.weight',\n 'blocks.6.1.bn2.weight',\n 'blocks.6.1.bn2.bias',\n 'blocks.6.1.se.conv_reduce.weight',\n 'blocks.6.1.se.conv_reduce.bias',\n 'blocks.6.1.se.conv_expand.weight',\n 'blocks.6.1.se.conv_expand.bias',\n 'blocks.6.1.conv_pwl.weight',\n 'blocks.6.1.bn3.weight',\n 'blocks.6.1.bn3.bias',\n 'conv_head.weight',\n 'bn2.weight',\n 'bn2.bias',\n 'classifier.weight',\n 'classifier.bias']"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_name"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): InvertedResidual(\n    (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNormAct2d(\n      1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n      (drop): Identity()\n      (act): SiLU(inplace=True)\n    )\n    (conv_dw): Conv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1248, bias=False)\n    (bn2): BatchNormAct2d(\n      1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n      (drop): Identity()\n      (act): SiLU(inplace=True)\n    )\n    (se): SqueezeExcite(\n      (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n      (act1): SiLU(inplace=True)\n      (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n      (gate): Sigmoid()\n    )\n    (conv_pwl): Conv2d(1248, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNormAct2d(\n      352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n      (drop): Identity()\n      (act): Identity()\n    )\n    (drop_path): Identity()\n  )\n  (1): InvertedResidual(\n    (conv_pw): Conv2d(352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNormAct2d(\n      2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n      (drop): Identity()\n      (act): SiLU(inplace=True)\n    )\n    (conv_dw): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2112, bias=False)\n    (bn2): BatchNormAct2d(\n      2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n      (drop): Identity()\n      (act): SiLU(inplace=True)\n    )\n    (se): SqueezeExcite(\n      (conv_reduce): Conv2d(2112, 88, kernel_size=(1, 1), stride=(1, 1))\n      (act1): SiLU(inplace=True)\n      (conv_expand): Conv2d(88, 2112, kernel_size=(1, 1), stride=(1, 1))\n      (gate): Sigmoid()\n    )\n    (conv_pwl): Conv2d(2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNormAct2d(\n      352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n      (drop): Identity()\n      (act): Identity()\n    )\n    (drop_path): Identity()\n  )\n)"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks.get_submodule(\"6\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_stem.weight False\n",
      "bn1.weight False\n",
      "bn1.bias False\n",
      "blocks.0.0.conv_dw.weight False\n",
      "blocks.0.0.bn1.weight False\n",
      "blocks.0.0.bn1.bias False\n",
      "blocks.0.0.se.conv_reduce.weight False\n",
      "blocks.0.0.se.conv_reduce.bias False\n",
      "blocks.0.0.se.conv_expand.weight False\n",
      "blocks.0.0.se.conv_expand.bias False\n",
      "blocks.0.0.conv_pw.weight False\n",
      "blocks.0.0.bn2.weight False\n",
      "blocks.0.0.bn2.bias False\n",
      "blocks.0.1.conv_dw.weight False\n",
      "blocks.0.1.bn1.weight False\n",
      "blocks.0.1.bn1.bias False\n",
      "blocks.0.1.se.conv_reduce.weight False\n",
      "blocks.0.1.se.conv_reduce.bias False\n",
      "blocks.0.1.se.conv_expand.weight False\n",
      "blocks.0.1.se.conv_expand.bias False\n",
      "blocks.0.1.conv_pw.weight False\n",
      "blocks.0.1.bn2.weight False\n",
      "blocks.0.1.bn2.bias False\n",
      "blocks.1.0.conv_pw.weight False\n",
      "blocks.1.0.bn1.weight False\n",
      "blocks.1.0.bn1.bias False\n",
      "blocks.1.0.conv_dw.weight False\n",
      "blocks.1.0.bn2.weight False\n",
      "blocks.1.0.bn2.bias False\n",
      "blocks.1.0.se.conv_reduce.weight False\n",
      "blocks.1.0.se.conv_reduce.bias False\n",
      "blocks.1.0.se.conv_expand.weight False\n",
      "blocks.1.0.se.conv_expand.bias False\n",
      "blocks.1.0.conv_pwl.weight False\n",
      "blocks.1.0.bn3.weight False\n",
      "blocks.1.0.bn3.bias False\n",
      "blocks.1.1.conv_pw.weight False\n",
      "blocks.1.1.bn1.weight False\n",
      "blocks.1.1.bn1.bias False\n",
      "blocks.1.1.conv_dw.weight False\n",
      "blocks.1.1.bn2.weight False\n",
      "blocks.1.1.bn2.bias False\n",
      "blocks.1.1.se.conv_reduce.weight False\n",
      "blocks.1.1.se.conv_reduce.bias False\n",
      "blocks.1.1.se.conv_expand.weight False\n",
      "blocks.1.1.se.conv_expand.bias False\n",
      "blocks.1.1.conv_pwl.weight False\n",
      "blocks.1.1.bn3.weight False\n",
      "blocks.1.1.bn3.bias False\n",
      "blocks.1.2.conv_pw.weight False\n",
      "blocks.1.2.bn1.weight False\n",
      "blocks.1.2.bn1.bias False\n",
      "blocks.1.2.conv_dw.weight False\n",
      "blocks.1.2.bn2.weight False\n",
      "blocks.1.2.bn2.bias False\n",
      "blocks.1.2.se.conv_reduce.weight False\n",
      "blocks.1.2.se.conv_reduce.bias False\n",
      "blocks.1.2.se.conv_expand.weight False\n",
      "blocks.1.2.se.conv_expand.bias False\n",
      "blocks.1.2.conv_pwl.weight False\n",
      "blocks.1.2.bn3.weight False\n",
      "blocks.1.2.bn3.bias False\n",
      "blocks.2.0.conv_pw.weight False\n",
      "blocks.2.0.bn1.weight False\n",
      "blocks.2.0.bn1.bias False\n",
      "blocks.2.0.conv_dw.weight False\n",
      "blocks.2.0.bn2.weight False\n",
      "blocks.2.0.bn2.bias False\n",
      "blocks.2.0.se.conv_reduce.weight False\n",
      "blocks.2.0.se.conv_reduce.bias False\n",
      "blocks.2.0.se.conv_expand.weight False\n",
      "blocks.2.0.se.conv_expand.bias False\n",
      "blocks.2.0.conv_pwl.weight False\n",
      "blocks.2.0.bn3.weight False\n",
      "blocks.2.0.bn3.bias False\n",
      "blocks.2.1.conv_pw.weight False\n",
      "blocks.2.1.bn1.weight False\n",
      "blocks.2.1.bn1.bias False\n",
      "blocks.2.1.conv_dw.weight False\n",
      "blocks.2.1.bn2.weight False\n",
      "blocks.2.1.bn2.bias False\n",
      "blocks.2.1.se.conv_reduce.weight False\n",
      "blocks.2.1.se.conv_reduce.bias False\n",
      "blocks.2.1.se.conv_expand.weight False\n",
      "blocks.2.1.se.conv_expand.bias False\n",
      "blocks.2.1.conv_pwl.weight False\n",
      "blocks.2.1.bn3.weight False\n",
      "blocks.2.1.bn3.bias False\n",
      "blocks.2.2.conv_pw.weight False\n",
      "blocks.2.2.bn1.weight False\n",
      "blocks.2.2.bn1.bias False\n",
      "blocks.2.2.conv_dw.weight False\n",
      "blocks.2.2.bn2.weight False\n",
      "blocks.2.2.bn2.bias False\n",
      "blocks.2.2.se.conv_reduce.weight False\n",
      "blocks.2.2.se.conv_reduce.bias False\n",
      "blocks.2.2.se.conv_expand.weight False\n",
      "blocks.2.2.se.conv_expand.bias False\n",
      "blocks.2.2.conv_pwl.weight False\n",
      "blocks.2.2.bn3.weight False\n",
      "blocks.2.2.bn3.bias False\n",
      "blocks.3.0.conv_pw.weight False\n",
      "blocks.3.0.bn1.weight False\n",
      "blocks.3.0.bn1.bias False\n",
      "blocks.3.0.conv_dw.weight False\n",
      "blocks.3.0.bn2.weight False\n",
      "blocks.3.0.bn2.bias False\n",
      "blocks.3.0.se.conv_reduce.weight False\n",
      "blocks.3.0.se.conv_reduce.bias False\n",
      "blocks.3.0.se.conv_expand.weight False\n",
      "blocks.3.0.se.conv_expand.bias False\n",
      "blocks.3.0.conv_pwl.weight False\n",
      "blocks.3.0.bn3.weight False\n",
      "blocks.3.0.bn3.bias False\n",
      "blocks.3.1.conv_pw.weight False\n",
      "blocks.3.1.bn1.weight False\n",
      "blocks.3.1.bn1.bias False\n",
      "blocks.3.1.conv_dw.weight False\n",
      "blocks.3.1.bn2.weight False\n",
      "blocks.3.1.bn2.bias False\n",
      "blocks.3.1.se.conv_reduce.weight False\n",
      "blocks.3.1.se.conv_reduce.bias False\n",
      "blocks.3.1.se.conv_expand.weight False\n",
      "blocks.3.1.se.conv_expand.bias False\n",
      "blocks.3.1.conv_pwl.weight False\n",
      "blocks.3.1.bn3.weight False\n",
      "blocks.3.1.bn3.bias False\n",
      "blocks.3.2.conv_pw.weight False\n",
      "blocks.3.2.bn1.weight False\n",
      "blocks.3.2.bn1.bias False\n",
      "blocks.3.2.conv_dw.weight False\n",
      "blocks.3.2.bn2.weight False\n",
      "blocks.3.2.bn2.bias False\n",
      "blocks.3.2.se.conv_reduce.weight False\n",
      "blocks.3.2.se.conv_reduce.bias False\n",
      "blocks.3.2.se.conv_expand.weight False\n",
      "blocks.3.2.se.conv_expand.bias False\n",
      "blocks.3.2.conv_pwl.weight False\n",
      "blocks.3.2.bn3.weight False\n",
      "blocks.3.2.bn3.bias False\n",
      "blocks.3.3.conv_pw.weight False\n",
      "blocks.3.3.bn1.weight False\n",
      "blocks.3.3.bn1.bias False\n",
      "blocks.3.3.conv_dw.weight False\n",
      "blocks.3.3.bn2.weight False\n",
      "blocks.3.3.bn2.bias False\n",
      "blocks.3.3.se.conv_reduce.weight False\n",
      "blocks.3.3.se.conv_reduce.bias False\n",
      "blocks.3.3.se.conv_expand.weight False\n",
      "blocks.3.3.se.conv_expand.bias False\n",
      "blocks.3.3.conv_pwl.weight False\n",
      "blocks.3.3.bn3.weight False\n",
      "blocks.3.3.bn3.bias False\n",
      "blocks.3.4.conv_pw.weight False\n",
      "blocks.3.4.bn1.weight False\n",
      "blocks.3.4.bn1.bias False\n",
      "blocks.3.4.conv_dw.weight False\n",
      "blocks.3.4.bn2.weight False\n",
      "blocks.3.4.bn2.bias False\n",
      "blocks.3.4.se.conv_reduce.weight False\n",
      "blocks.3.4.se.conv_reduce.bias False\n",
      "blocks.3.4.se.conv_expand.weight False\n",
      "blocks.3.4.se.conv_expand.bias False\n",
      "blocks.3.4.conv_pwl.weight False\n",
      "blocks.3.4.bn3.weight False\n",
      "blocks.3.4.bn3.bias False\n",
      "blocks.4.0.conv_pw.weight False\n",
      "blocks.4.0.bn1.weight False\n",
      "blocks.4.0.bn1.bias False\n",
      "blocks.4.0.conv_dw.weight False\n",
      "blocks.4.0.bn2.weight False\n",
      "blocks.4.0.bn2.bias False\n",
      "blocks.4.0.se.conv_reduce.weight False\n",
      "blocks.4.0.se.conv_reduce.bias False\n",
      "blocks.4.0.se.conv_expand.weight False\n",
      "blocks.4.0.se.conv_expand.bias False\n",
      "blocks.4.0.conv_pwl.weight False\n",
      "blocks.4.0.bn3.weight False\n",
      "blocks.4.0.bn3.bias False\n",
      "blocks.4.1.conv_pw.weight False\n",
      "blocks.4.1.bn1.weight False\n",
      "blocks.4.1.bn1.bias False\n",
      "blocks.4.1.conv_dw.weight False\n",
      "blocks.4.1.bn2.weight False\n",
      "blocks.4.1.bn2.bias False\n",
      "blocks.4.1.se.conv_reduce.weight False\n",
      "blocks.4.1.se.conv_reduce.bias False\n",
      "blocks.4.1.se.conv_expand.weight False\n",
      "blocks.4.1.se.conv_expand.bias False\n",
      "blocks.4.1.conv_pwl.weight False\n",
      "blocks.4.1.bn3.weight False\n",
      "blocks.4.1.bn3.bias False\n",
      "blocks.4.2.conv_pw.weight False\n",
      "blocks.4.2.bn1.weight False\n",
      "blocks.4.2.bn1.bias False\n",
      "blocks.4.2.conv_dw.weight False\n",
      "blocks.4.2.bn2.weight False\n",
      "blocks.4.2.bn2.bias False\n",
      "blocks.4.2.se.conv_reduce.weight False\n",
      "blocks.4.2.se.conv_reduce.bias False\n",
      "blocks.4.2.se.conv_expand.weight False\n",
      "blocks.4.2.se.conv_expand.bias False\n",
      "blocks.4.2.conv_pwl.weight False\n",
      "blocks.4.2.bn3.weight False\n",
      "blocks.4.2.bn3.bias False\n",
      "blocks.4.3.conv_pw.weight False\n",
      "blocks.4.3.bn1.weight False\n",
      "blocks.4.3.bn1.bias False\n",
      "blocks.4.3.conv_dw.weight False\n",
      "blocks.4.3.bn2.weight False\n",
      "blocks.4.3.bn2.bias False\n",
      "blocks.4.3.se.conv_reduce.weight False\n",
      "blocks.4.3.se.conv_reduce.bias False\n",
      "blocks.4.3.se.conv_expand.weight False\n",
      "blocks.4.3.se.conv_expand.bias False\n",
      "blocks.4.3.conv_pwl.weight False\n",
      "blocks.4.3.bn3.weight False\n",
      "blocks.4.3.bn3.bias False\n",
      "blocks.4.4.conv_pw.weight False\n",
      "blocks.4.4.bn1.weight False\n",
      "blocks.4.4.bn1.bias False\n",
      "blocks.4.4.conv_dw.weight False\n",
      "blocks.4.4.bn2.weight False\n",
      "blocks.4.4.bn2.bias False\n",
      "blocks.4.4.se.conv_reduce.weight False\n",
      "blocks.4.4.se.conv_reduce.bias False\n",
      "blocks.4.4.se.conv_expand.weight False\n",
      "blocks.4.4.se.conv_expand.bias False\n",
      "blocks.4.4.conv_pwl.weight False\n",
      "blocks.4.4.bn3.weight False\n",
      "blocks.4.4.bn3.bias False\n",
      "blocks.5.0.conv_pw.weight False\n",
      "blocks.5.0.bn1.weight False\n",
      "blocks.5.0.bn1.bias False\n",
      "blocks.5.0.conv_dw.weight False\n",
      "blocks.5.0.bn2.weight False\n",
      "blocks.5.0.bn2.bias False\n",
      "blocks.5.0.se.conv_reduce.weight False\n",
      "blocks.5.0.se.conv_reduce.bias False\n",
      "blocks.5.0.se.conv_expand.weight False\n",
      "blocks.5.0.se.conv_expand.bias False\n",
      "blocks.5.0.conv_pwl.weight False\n",
      "blocks.5.0.bn3.weight False\n",
      "blocks.5.0.bn3.bias False\n",
      "blocks.5.1.conv_pw.weight False\n",
      "blocks.5.1.bn1.weight False\n",
      "blocks.5.1.bn1.bias False\n",
      "blocks.5.1.conv_dw.weight False\n",
      "blocks.5.1.bn2.weight False\n",
      "blocks.5.1.bn2.bias False\n",
      "blocks.5.1.se.conv_reduce.weight False\n",
      "blocks.5.1.se.conv_reduce.bias False\n",
      "blocks.5.1.se.conv_expand.weight False\n",
      "blocks.5.1.se.conv_expand.bias False\n",
      "blocks.5.1.conv_pwl.weight False\n",
      "blocks.5.1.bn3.weight False\n",
      "blocks.5.1.bn3.bias False\n",
      "blocks.5.2.conv_pw.weight False\n",
      "blocks.5.2.bn1.weight False\n",
      "blocks.5.2.bn1.bias False\n",
      "blocks.5.2.conv_dw.weight False\n",
      "blocks.5.2.bn2.weight False\n",
      "blocks.5.2.bn2.bias False\n",
      "blocks.5.2.se.conv_reduce.weight False\n",
      "blocks.5.2.se.conv_reduce.bias False\n",
      "blocks.5.2.se.conv_expand.weight False\n",
      "blocks.5.2.se.conv_expand.bias False\n",
      "blocks.5.2.conv_pwl.weight False\n",
      "blocks.5.2.bn3.weight False\n",
      "blocks.5.2.bn3.bias False\n",
      "blocks.5.3.conv_pw.weight False\n",
      "blocks.5.3.bn1.weight False\n",
      "blocks.5.3.bn1.bias False\n",
      "blocks.5.3.conv_dw.weight False\n",
      "blocks.5.3.bn2.weight False\n",
      "blocks.5.3.bn2.bias False\n",
      "blocks.5.3.se.conv_reduce.weight False\n",
      "blocks.5.3.se.conv_reduce.bias False\n",
      "blocks.5.3.se.conv_expand.weight False\n",
      "blocks.5.3.se.conv_expand.bias False\n",
      "blocks.5.3.conv_pwl.weight False\n",
      "blocks.5.3.bn3.weight False\n",
      "blocks.5.3.bn3.bias False\n",
      "blocks.5.4.conv_pw.weight False\n",
      "blocks.5.4.bn1.weight False\n",
      "blocks.5.4.bn1.bias False\n",
      "blocks.5.4.conv_dw.weight False\n",
      "blocks.5.4.bn2.weight False\n",
      "blocks.5.4.bn2.bias False\n",
      "blocks.5.4.se.conv_reduce.weight False\n",
      "blocks.5.4.se.conv_reduce.bias False\n",
      "blocks.5.4.se.conv_expand.weight False\n",
      "blocks.5.4.se.conv_expand.bias False\n",
      "blocks.5.4.conv_pwl.weight False\n",
      "blocks.5.4.bn3.weight False\n",
      "blocks.5.4.bn3.bias False\n",
      "blocks.5.5.conv_pw.weight False\n",
      "blocks.5.5.bn1.weight False\n",
      "blocks.5.5.bn1.bias False\n",
      "blocks.5.5.conv_dw.weight False\n",
      "blocks.5.5.bn2.weight False\n",
      "blocks.5.5.bn2.bias False\n",
      "blocks.5.5.se.conv_reduce.weight False\n",
      "blocks.5.5.se.conv_reduce.bias False\n",
      "blocks.5.5.se.conv_expand.weight False\n",
      "blocks.5.5.se.conv_expand.bias False\n",
      "blocks.5.5.conv_pwl.weight False\n",
      "blocks.5.5.bn3.weight False\n",
      "blocks.5.5.bn3.bias False\n",
      "blocks.6.0.conv_pw.weight True\n",
      "blocks.6.0.bn1.weight True\n",
      "blocks.6.0.bn1.bias True\n",
      "blocks.6.0.conv_dw.weight True\n",
      "blocks.6.0.bn2.weight True\n",
      "blocks.6.0.bn2.bias True\n",
      "blocks.6.0.se.conv_reduce.weight True\n",
      "blocks.6.0.se.conv_reduce.bias True\n",
      "blocks.6.0.se.conv_expand.weight True\n",
      "blocks.6.0.se.conv_expand.bias True\n",
      "blocks.6.0.conv_pwl.weight True\n",
      "blocks.6.0.bn3.weight True\n",
      "blocks.6.0.bn3.bias True\n",
      "blocks.6.1.conv_pw.weight True\n",
      "blocks.6.1.bn1.weight True\n",
      "blocks.6.1.bn1.bias True\n",
      "blocks.6.1.conv_dw.weight True\n",
      "blocks.6.1.bn2.weight True\n",
      "blocks.6.1.bn2.bias True\n",
      "blocks.6.1.se.conv_reduce.weight True\n",
      "blocks.6.1.se.conv_reduce.bias True\n",
      "blocks.6.1.se.conv_expand.weight True\n",
      "blocks.6.1.se.conv_expand.bias True\n",
      "blocks.6.1.conv_pwl.weight True\n",
      "blocks.6.1.bn3.weight True\n",
      "blocks.6.1.bn3.bias True\n",
      "conv_head.weight True\n",
      "bn2.weight True\n",
      "bn2.bias True\n",
      "classifier.weight True\n",
      "classifier.bias True\n"
     ]
    }
   ],
   "source": [
    "requires_grad = False\n",
    "for i, module in enumerate(model.named_parameters()):\n",
    "    name, param = module\n",
    "    if \"blocks.6\" in name:\n",
    "        requires_grad = True\n",
    "    param.requires_grad = requires_grad\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                  0\nurl               https://github.com/rwightman/pytorch-image-mod...\nhf_hub_id                              timm/efficientnet_b2.ra_in1k\narchitecture                                        efficientnet_b2\ntag                                                         ra_in1k\ncustom_load                                                   False\ninput_size                                            (3, 256, 256)\ntest_input_size                                       (3, 288, 288)\nfixed_input_size                                              False\ninterpolation                                               bicubic\ncrop_pct                                                        1.0\ncrop_mode                                                    center\nmean                                          (0.485, 0.456, 0.406)\nstd                                           (0.229, 0.224, 0.225)\nnum_classes                                                    1000\npool_size                                                    (8, 8)\nfirst_conv                                                conv_stem\nclassifier                                               classifier",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>url</th>\n      <td>https://github.com/rwightman/pytorch-image-mod...</td>\n    </tr>\n    <tr>\n      <th>hf_hub_id</th>\n      <td>timm/efficientnet_b2.ra_in1k</td>\n    </tr>\n    <tr>\n      <th>architecture</th>\n      <td>efficientnet_b2</td>\n    </tr>\n    <tr>\n      <th>tag</th>\n      <td>ra_in1k</td>\n    </tr>\n    <tr>\n      <th>custom_load</th>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>input_size</th>\n      <td>(3, 256, 256)</td>\n    </tr>\n    <tr>\n      <th>test_input_size</th>\n      <td>(3, 288, 288)</td>\n    </tr>\n    <tr>\n      <th>fixed_input_size</th>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>interpolation</th>\n      <td>bicubic</td>\n    </tr>\n    <tr>\n      <th>crop_pct</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>crop_mode</th>\n      <td>center</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>(0.485, 0.456, 0.406)</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>(0.229, 0.224, 0.225)</td>\n    </tr>\n    <tr>\n      <th>num_classes</th>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>pool_size</th>\n      <td>(8, 8)</td>\n    </tr>\n    <tr>\n      <th>first_conv</th>\n      <td>conv_stem</td>\n    </tr>\n    <tr>\n      <th>classifier</th>\n      <td>classifier</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(model.default_cfg, orient=\"index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "Compose(\n    Resize(size=284, interpolation=bicubic, max_size=None, antialias=None)\n    CenterCrop(size=(256, 256))\n    ToTensor()\n    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n)"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "(256, 256)"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.default_cfg[\"input_size\"][1:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "Resize(size=256, interpolation=bicubic, max_size=None, antialias=None)"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "transforms.Resize(size=256, interpolation=InterpolationMode.BICUBIC)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Custom final layer\n",
    "num_in_features = model.get_classifier().in_features\n",
    "model.head.fc = nn.Sequential(\n",
    "    nn.BatchNorm1d(num_in_features),\n",
    "    nn.Linear(in_features=num_in_features, out_features=512, bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=512, out_features=10, bias=False)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 10])"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(torch.randn(1, 3, 256, 256)).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'num_chs': 64, 'reduction': 4, 'module': 'stages.0'},\n {'num_chs': 128, 'reduction': 8, 'module': 'stages.1'},\n {'num_chs': 256, 'reduction': 16, 'module': 'stages.2'},\n {'num_chs': 512, 'reduction': 32, 'module': 'stages.3'}]"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_info"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
