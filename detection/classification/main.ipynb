{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\tf-torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchinfo\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [],
   "source": [
    "import torchmetrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "outputs": [],
   "source": [
    "task = \"multiclass\"\n",
    "top_k = 1\n",
    "accuracy = torchmetrics.classification.Accuracy(task=task, threshold=0.5, num_classes=10, top_k=top_k).to(\"cuda\")\n",
    "precision = torchmetrics.Precision(task=task, threshold=0.5, num_classes=10, top_k=top_k).to(\"cuda\")\n",
    "recall = torchmetrics.Recall(task=task, threshold=0.5, num_classes=10, top_k=top_k).to(\"cuda\")\n",
    "f1 = torchmetrics.F1Score(task=task, threshold=0.5, num_classes=10, top_k=top_k).to(\"cuda\")\n",
    "stat = torchmetrics.StatScores(task=task, threshold=0.5, num_classes=10, top_k=top_k).to(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  9, 81,  9, 10], device='cuda:0')\n",
      "tensor(0.1000, device='cuda:0')\n",
      "tensor(0.1000, device='cuda:0')\n",
      "tensor(0.1000, device='cuda:0')\n",
      "tensor(0.1000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "preds = torch.tensor([[-0.0129, -0.3175, -0.0683,  0.2080,  0.1129,  0.0553,  0.0140,  0.0251,\n",
    "         -0.1527,  0.0622],\n",
    "        [ 0.1304,  0.1785,  0.0883,  0.5066, -0.1161, -0.1496, -0.2035,  0.0709,\n",
    "          0.2420,  0.3981],\n",
    "        [-0.0213, -0.0850, -0.1686,  0.1521,  0.2414, -0.0275,  0.0066,  0.1848,\n",
    "         -0.1766,  0.0321],\n",
    "        [ 0.3734,  0.3885, -0.2002, -0.3148, -0.2604,  0.3571, -0.7075, -0.2140,\n",
    "          0.2051,  0.7275],\n",
    "        [-0.1535, -0.1203, -0.0069,  0.2753,  0.3317, -0.3602, -0.1358,  0.1422,\n",
    "         -0.0302,  0.3005],\n",
    "        [ 0.2874,  0.1921,  0.2205,  0.3036, -0.1055, -0.1325,  0.0322,  0.4317,\n",
    "          0.1032, -0.0067],\n",
    "        [ 0.0414, -0.1034, -0.1293,  0.0489,  0.3273,  0.1023, -0.1438,  0.1175,\n",
    "         -0.0843,  0.1121],\n",
    "        [-0.1684, -0.0975, -0.1321,  0.1957,  0.1615,  0.1282, -0.2379,  0.0721,\n",
    "         -0.1267,  0.1032],\n",
    "        [ 0.0425, -0.1601, -0.0020,  0.1313,  0.1604,  0.1026,  0.0792,  0.1182,\n",
    "         -0.0664,  0.0552],\n",
    "        [-0.0258, -0.2268, -0.0416,  0.0605,  0.1985,  0.0211, -0.2180,  0.1641,\n",
    "         -0.0347, -0.0319]]).to(\"cuda\")\n",
    "target = torch.tensor([3, 7, 0, 1, 3, 8, 9, 8, 3, 6]).to(\"cuda\")\n",
    "print(stat(preds, target))\n",
    "print(accuracy(preds, target))\n",
    "print(precision(preds, target))\n",
    "print(recall(preds, target))\n",
    "print(f1(preds, target))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4, 46, 44,  6, 10], device='cuda:0')\n",
      "tensor(0.4000, device='cuda:0')\n",
      "tensor(0.0800, device='cuda:0')\n",
      "tensor(0.4000, device='cuda:0')\n",
      "tensor(0.1333, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(stat.compute())\n",
    "print(accuracy.compute())\n",
    "print(precision.compute())\n",
    "print(recall.compute())\n",
    "print(f1.compute())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [
    "root_path = f\"C:/Users/conon/Documents/Datasets/cifar10/\"\n",
    "train_path = os.path.join(root_path, \"train\")\n",
    "val_path = os.path.join(root_path, \"test\")\n",
    "\n",
    "train_labels_path = os.path.join(root_path, \"train_labels.csv\")\n",
    "val_labels_path = os.path.join(root_path, \"test_labels.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train = datasets.CIFAR10(root=root_path, train=True, download=True)\n",
    "val = datasets.CIFAR10(root=root_path, train=False, download=True)\n",
    "\n",
    "for i, img in enumerate(train.data):\n",
    "     np.save(os.path.join(root_path + \"train\", str(i)), img)\n",
    "pd.DataFrame({\"label\": train.targets}).to_csv(train_labels_path, index=True)\n",
    "for i, img in enumerate(val.data):\n",
    "     np.save(os.path.join(root_path + \"test\", str(i)), img)\n",
    "pd.DataFrame({\"label\": val.targets}).to_csv(val_labels_path, index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "data": {
      "text/plain": "['vgg11.tv_in1k',\n 'vgg11_bn.tv_in1k',\n 'vgg13.tv_in1k',\n 'vgg13_bn.tv_in1k',\n 'vgg16.tv_in1k',\n 'vgg16_bn.tv_in1k',\n 'vgg19.tv_in1k',\n 'vgg19_bn.tv_in1k']"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(\"vgg*\", pretrained=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [],
   "source": [
    "model = timm.create_model(\"vgg11\", pretrained=True, num_classes=10, in_chans=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nVGG                                      [1, 10]                   --\n├─Sequential: 1-1                        [1, 512, 1, 1]            --\n│    └─Conv2d: 2-1                       [1, 64, 32, 32]           1,792\n│    └─ReLU: 2-2                         [1, 64, 32, 32]           --\n│    └─MaxPool2d: 2-3                    [1, 64, 16, 16]           --\n│    └─Conv2d: 2-4                       [1, 128, 16, 16]          73,856\n│    └─ReLU: 2-5                         [1, 128, 16, 16]          --\n│    └─MaxPool2d: 2-6                    [1, 128, 8, 8]            --\n│    └─Conv2d: 2-7                       [1, 256, 8, 8]            295,168\n│    └─ReLU: 2-8                         [1, 256, 8, 8]            --\n│    └─Conv2d: 2-9                       [1, 256, 8, 8]            590,080\n│    └─ReLU: 2-10                        [1, 256, 8, 8]            --\n│    └─MaxPool2d: 2-11                   [1, 256, 4, 4]            --\n│    └─Conv2d: 2-12                      [1, 512, 4, 4]            1,180,160\n│    └─ReLU: 2-13                        [1, 512, 4, 4]            --\n│    └─Conv2d: 2-14                      [1, 512, 4, 4]            2,359,808\n│    └─ReLU: 2-15                        [1, 512, 4, 4]            --\n│    └─MaxPool2d: 2-16                   [1, 512, 2, 2]            --\n│    └─Conv2d: 2-17                      [1, 512, 2, 2]            2,359,808\n│    └─ReLU: 2-18                        [1, 512, 2, 2]            --\n│    └─Conv2d: 2-19                      [1, 512, 2, 2]            2,359,808\n│    └─ReLU: 2-20                        [1, 512, 2, 2]            --\n│    └─MaxPool2d: 2-21                   [1, 512, 1, 1]            --\n├─ConvMlp: 1-2                           [1, 4096, 1, 1]           --\n│    └─Conv2d: 2-22                      [1, 4096, 1, 1]           102,764,544\n│    └─ReLU: 2-23                        [1, 4096, 1, 1]           --\n│    └─Dropout: 2-24                     [1, 4096, 1, 1]           --\n│    └─Conv2d: 2-25                      [1, 4096, 1, 1]           16,781,312\n│    └─ReLU: 2-26                        [1, 4096, 1, 1]           --\n├─ClassifierHead: 1-3                    [1, 10]                   --\n│    └─SelectAdaptivePool2d: 2-27        [1, 4096]                 --\n│    │    └─AdaptiveAvgPool2d: 3-1       [1, 4096, 1, 1]           --\n│    │    └─Flatten: 3-2                 [1, 4096]                 --\n│    └─Dropout: 2-28                     [1, 4096]                 --\n│    └─Linear: 2-29                      [1, 10]                   40,970\n│    └─Identity: 2-30                    [1, 10]                   --\n==========================================================================================\nTotal params: 128,807,306\nTrainable params: 128,807,306\nNon-trainable params: 0\nTotal mult-adds (M): 272.50\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 1.28\nParams size (MB): 515.23\nEstimated Total Size (MB): 516.52\n=========================================================================================="
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model, input_size=[1, 3, 32, 32], depth=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "param_name = [name for name,_ in model.named_parameters()] # All parameters name\n",
    "layer_name = [name for name,_ in model.named_modules()] # All layers name"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "data": {
      "text/plain": "['features.0.weight',\n 'features.0.bias',\n 'features.3.weight',\n 'features.3.bias',\n 'features.6.weight',\n 'features.6.bias',\n 'features.8.weight',\n 'features.8.bias',\n 'features.11.weight',\n 'features.11.bias',\n 'features.13.weight',\n 'features.13.bias',\n 'features.16.weight',\n 'features.16.bias',\n 'features.18.weight',\n 'features.18.bias',\n 'pre_logits.fc1.weight',\n 'pre_logits.fc1.bias',\n 'pre_logits.fc2.weight',\n 'pre_logits.fc2.bias',\n 'head.fc.weight',\n 'head.fc.bias']"
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_name"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "data": {
      "text/plain": "VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (12): ReLU(inplace=True)\n    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (14): ReLU(inplace=True)\n    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (17): ReLU(inplace=True)\n    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (19): ReLU(inplace=True)\n    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (pre_logits): ConvMlp(\n    (fc1): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n    (act1): ReLU(inplace=True)\n    (drop): Dropout(p=0.0, inplace=False)\n    (fc2): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n    (act2): ReLU(inplace=True)\n  )\n  (head): ClassifierHead(\n    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n    (drop): Dropout(p=0.0, inplace=False)\n    (fc): Linear(in_features=4096, out_features=10, bias=True)\n    (flatten): Identity()\n  )\n)"
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight False\n",
      "features.0.bias False\n",
      "features.3.weight False\n",
      "features.3.bias False\n",
      "features.6.weight False\n",
      "features.6.bias False\n",
      "features.8.weight False\n",
      "features.8.bias False\n",
      "features.11.weight False\n",
      "features.11.bias False\n",
      "features.13.weight False\n",
      "features.13.bias False\n",
      "features.16.weight False\n",
      "features.16.bias False\n",
      "features.18.weight False\n",
      "features.18.bias False\n",
      "pre_logits.fc1.weight True\n",
      "pre_logits.fc1.bias True\n",
      "pre_logits.fc2.weight True\n",
      "pre_logits.fc2.bias True\n",
      "head.fc.weight True\n",
      "head.fc.bias True\n"
     ]
    }
   ],
   "source": [
    "requires_grad = False\n",
    "for i, module in enumerate(model.named_parameters()):\n",
    "    name, param = module\n",
    "    if \"pre_logits\" in name:\n",
    "        requires_grad = True\n",
    "    param.requires_grad = requires_grad\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [
    {
     "data": {
      "text/plain": "                                      0\nurl                                    \nhf_hub_id            timm/vgg11.tv_in1k\narchitecture                      vgg11\ntag                             tv_in1k\ncustom_load                       False\ninput_size                (3, 224, 224)\nfixed_input_size                  False\ninterpolation                  bilinear\ncrop_pct                          0.875\ncrop_mode                        center\nmean              (0.485, 0.456, 0.406)\nstd               (0.229, 0.224, 0.225)\nnum_classes                        1000\npool_size                        (7, 7)\nfirst_conv                   features.0\nclassifier                      head.fc",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>url</th>\n      <td></td>\n    </tr>\n    <tr>\n      <th>hf_hub_id</th>\n      <td>timm/vgg11.tv_in1k</td>\n    </tr>\n    <tr>\n      <th>architecture</th>\n      <td>vgg11</td>\n    </tr>\n    <tr>\n      <th>tag</th>\n      <td>tv_in1k</td>\n    </tr>\n    <tr>\n      <th>custom_load</th>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>input_size</th>\n      <td>(3, 224, 224)</td>\n    </tr>\n    <tr>\n      <th>fixed_input_size</th>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>interpolation</th>\n      <td>bilinear</td>\n    </tr>\n    <tr>\n      <th>crop_pct</th>\n      <td>0.875</td>\n    </tr>\n    <tr>\n      <th>crop_mode</th>\n      <td>center</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>(0.485, 0.456, 0.406)</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>(0.229, 0.224, 0.225)</td>\n    </tr>\n    <tr>\n      <th>num_classes</th>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>pool_size</th>\n      <td>(7, 7)</td>\n    </tr>\n    <tr>\n      <th>first_conv</th>\n      <td>features.0</td>\n    </tr>\n    <tr>\n      <th>classifier</th>\n      <td>head.fc</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(model.default_cfg, orient=\"index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "Compose(\n    Resize(size=284, interpolation=bicubic, max_size=None, antialias=None)\n    CenterCrop(size=(256, 256))\n    ToTensor()\n    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n)"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "(256, 256)"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.default_cfg[\"input_size\"][1:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "Resize(size=256, interpolation=bicubic, max_size=None, antialias=None)"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "transforms.Resize(size=256, interpolation=InterpolationMode.BICUBIC)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Custom final layer\n",
    "num_in_features = model.get_classifier().in_features\n",
    "model.head.fc = nn.Sequential(\n",
    "    nn.BatchNorm1d(num_in_features),\n",
    "    nn.Linear(in_features=num_in_features, out_features=512, bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=512, out_features=10, bias=False)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 10])"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(torch.randn(1, 3, 256, 256)).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'num_chs': 64, 'reduction': 4, 'module': 'stages.0'},\n {'num_chs': 128, 'reduction': 8, 'module': 'stages.1'},\n {'num_chs': 256, 'reduction': 16, 'module': 'stages.2'},\n {'num_chs': 512, 'reduction': 32, 'module': 'stages.3'}]"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_info"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
